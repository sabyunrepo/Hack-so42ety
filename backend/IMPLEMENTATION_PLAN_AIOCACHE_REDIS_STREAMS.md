# aiocache + Redis Streams êµ¬í˜„ ê³„íš

## ğŸ“‹ ì „ì²´ ê°œìš”

### ëª©í‘œ
- aiocacheë¥¼ í™œìš©í•œ ë¹„ë™ê¸° ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•
- Redis Streams ê¸°ë°˜ ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ìºì‹œ ë¬´íš¨í™”
- ë°ì½”ë ˆì´í„° íŒ¨í„´ìœ¼ë¡œ ê°„ê²°í•œ ì½”ë“œ
- ì™„ë²½í•œ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### ê¸°ìˆ  ìŠ¤íƒ
- **ìºì‹±**: aiocache (Redis ë°±ì—”ë“œ)
- **ì´ë²¤íŠ¸**: Redis Streams
- **í”„ë ˆì„ì›Œí¬**: FastAPI
- **ì¸í”„ë¼**: Docker Compose

---

## ğŸ”„ Phaseë³„ êµ¬í˜„ ë£¨í”„

ê° PhaseëŠ” ë‹¤ìŒ ë£¨í”„ë¥¼ ë”°ë¦…ë‹ˆë‹¤:

```
Phase ì‹œì‘
    â†“
1. êµ¬í˜„ (Implementation)
    â†“
2. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Tests)
    â†“
3. í†µí•© í…ŒìŠ¤íŠ¸ (Integration Tests)
    â†“
4. ë””ë²„ê¹… (Debugging)
    â†“
5. ê²€ì¦ (Verification)
    â†“
6. ë¬¸ì„œí™” (Documentation)
    â†“
Phase ì™„ë£Œ â†’ ë‹¤ìŒ Phase
```

---

## Phase 1: ì¸í”„ë¼ êµ¬ì¶• ë° ê¸°ë³¸ ì„¤ì •

### ëª©í‘œ
- Redis ì»¨í…Œì´ë„ˆ ì¶”ê°€
- aiocache ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
- ê¸°ë³¸ ì„¤ì • íŒŒì¼ êµ¬ì„±
- ì—°ê²° í…ŒìŠ¤íŠ¸

### ì‘ì—… ëª©ë¡

#### 1.1 Docker Compose ìˆ˜ì •
- [ ] Redis ì„œë¹„ìŠ¤ ì¶”ê°€
- [ ] Redis Streams ì§€ì› í™•ì¸
- [ ] Health check ì„¤ì •
- [ ] ë„¤íŠ¸ì›Œí¬ ì„¤ì • í™•ì¸

#### 1.2 requirements.txt ì—…ë°ì´íŠ¸
- [ ] aiocache ì¶”ê°€
- [ ] aioredis ë²„ì „ í™•ì¸ (ì´ë¯¸ ìˆìŒ)
- [ ] ì˜ì¡´ì„± ì¶©ëŒ í™•ì¸

#### 1.3 ì„¤ì • íŒŒì¼ ì¶”ê°€
- [ ] Redis ì—°ê²° ì„¤ì • ì¶”ê°€
- [ ] aiocache ì„¤ì • ì¶”ê°€
- [ ] í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€

#### 1.4 ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
- [ ] Redis ì—°ê²° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- [ ] aiocache ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
- [ ] Streams ìƒì„± í…ŒìŠ¤íŠ¸

### êµ¬í˜„ ì½”ë“œ

#### 1.1 Docker Compose ìˆ˜ì •
```yaml
# docker-compose.ymlì— ì¶”ê°€
services:
  redis:
    image: redis:7-alpine
    container_name: moriai-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    networks:
      - moriai-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  redis-data:
```

#### 1.2 requirements.txt ì—…ë°ì´íŠ¸
```txt
# ì¶”ê°€
aiocache==0.12.2
```

#### 1.3 ì„¤ì • íŒŒì¼
```python
# backend/core/config.pyì— ì¶”ê°€
redis_host: str = Field(default="redis", env="REDIS_HOST")
redis_port: int = Field(default=6379, env="REDIS_PORT")
redis_url: str = Field(default="redis://redis:6379", env="REDIS_URL")

@property
def aiocache_config(self) -> dict:
    """aiocache ì„¤ì •"""
    return {
        "cache": "aiocache.RedisCache",
        "endpoint": self.redis_host,
        "port": self.redis_port,
        "timeout": 1,
        "serializer": {
            "class": "aiocache.serializers.JsonSerializer"
        }
    }
```

### í…ŒìŠ¤íŠ¸ ê³„íš

#### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_redis_connection.py
async def test_redis_connection():
    """Redis ì—°ê²° í…ŒìŠ¤íŠ¸"""
    redis = await aioredis.from_url("redis://redis:6379")
    await redis.ping()
    assert True

async def test_redis_streams():
    """Redis Streams ìƒì„± í…ŒìŠ¤íŠ¸"""
    redis = await aioredis.from_url("redis://redis:6379")
    await redis.xadd("test:stream", {"test": "data"})
    messages = await redis.xread({"test:stream": "0"}, count=1)
    assert len(messages) > 0
```

#### í†µí•© í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_aiocache_setup.py
async def test_aiocache_initialization():
    """aiocache ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    from aiocache import Cache
    cache = Cache(Cache.REDIS, endpoint="redis", port=6379)
    await cache.set("test", "value")
    result = await cache.get("test")
    assert result == "value"
```

### ê²€ì¦ ê¸°ì¤€
- [ ] Redis ì»¨í…Œì´ë„ˆ ì •ìƒ ì‹¤í–‰
- [ ] Redis ì—°ê²° ì„±ê³µ
- [ ] Streams ìƒì„±/ì½ê¸° ì„±ê³µ
- [ ] aiocache ì´ˆê¸°í™” ì„±ê³µ
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼

### ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Redis ë¡œê·¸ í™•ì¸: `docker-compose logs redis`
- [ ] Redis CLI ì ‘ì†: `docker-compose exec redis redis-cli`
- [ ] Streams í™•ì¸: `XINFO STREAM events:voice`
- [ ] ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸: `docker network inspect`

### ë¡¤ë°± ê³„íš
- Redis ì„œë¹„ìŠ¤ë§Œ ì œê±°í•˜ë©´ ê¸°ì¡´ ì‹œìŠ¤í…œì— ì˜í–¥ ì—†ìŒ

---

## Phase 2: ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• (Redis Streams)

### ëª©í‘œ
- Redis Streams ê¸°ë°˜ Event Bus êµ¬í˜„
- ì´ë²¤íŠ¸ íƒ€ì… ì •ì˜
- Consumer Groups ì„¤ì •
- ì´ë²¤íŠ¸ ë°œí–‰/êµ¬ë… í…ŒìŠ¤íŠ¸

### ì‘ì—… ëª©ë¡

#### 2.1 ì´ë²¤íŠ¸ íƒ€ì… ì •ì˜
- [ ] EventType enum ìƒì„±
- [ ] Event ëª¨ë¸ ìƒì„±
- [ ] ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ì •ì˜

#### 2.2 Event Bus ì¸í„°í˜ì´ìŠ¤
- [ ] EventBus ì¶”ìƒ í´ë˜ìŠ¤
- [ ] publish ë©”ì„œë“œ ì •ì˜
- [ ] subscribe ë©”ì„œë“œ ì •ì˜
- [ ] start/stop ë©”ì„œë“œ ì •ì˜

#### 2.3 Redis Streams êµ¬í˜„
- [ ] RedisStreamsEventBus í´ë˜ìŠ¤
- [ ] ì´ë²¤íŠ¸ ë°œí–‰ ë¡œì§
- [ ] Consumer Groups ì„¤ì •
- [ ] ì´ë²¤íŠ¸ ìˆ˜ì‹  ë£¨í”„
- [ ] ACK ì²˜ë¦¬

#### 2.4 FastAPI í†µí•©
- [ ] lifespanì—ì„œ Event Bus ì‹œì‘/ì¤‘ì§€
- [ ] ì˜ì¡´ì„± ì£¼ì… ì„¤ì •

### êµ¬í˜„ ì½”ë“œ

#### 2.1 ì´ë²¤íŠ¸ íƒ€ì… ì •ì˜
```python
# backend/core/events/types.py
from enum import Enum
from pydantic import BaseModel
from datetime import datetime
from typing import Dict, Any
import uuid

class EventType(str, Enum):
    """ì´ë²¤íŠ¸ íƒ€ì…"""
    VOICE_CREATED = "voice.created"
    VOICE_UPDATED = "voice.updated"
    VOICE_DELETED = "voice.deleted"

class Event(BaseModel):
    """ì´ë²¤íŠ¸ ê¸°ë³¸ êµ¬ì¡°"""
    type: EventType
    payload: Dict[str, Any]
    timestamp: datetime
    source: str
    event_id: str
    
    @classmethod
    def create(cls, event_type: EventType, payload: Dict[str, Any], source: str = "unknown"):
        return cls(
            type=event_type,
            payload=payload,
            timestamp=datetime.utcnow(),
            source=source,
            event_id=str(uuid.uuid4())
        )
```

#### 2.2 Event Bus ì¸í„°í˜ì´ìŠ¤
```python
# backend/core/events/bus.py
from abc import ABC, abstractmethod
from typing import Callable, Awaitable
from .types import Event, EventType

class EventBus(ABC):
    """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def publish(self, event_type: EventType, payload: dict) -> None:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        pass
    
    @abstractmethod
    async def subscribe(
        self,
        event_type: EventType,
        handler: Callable[[Event], Awaitable[None]]
    ) -> None:
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        pass
    
    @abstractmethod
    async def start(self, consumer_name: str = "worker-1") -> None:
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘"""
        pass
    
    @abstractmethod
    async def stop(self) -> None:
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¤‘ì§€"""
        pass
```

#### 2.3 Redis Streams êµ¬í˜„
```python
# backend/core/events/redis_streams_bus.py
import json
import asyncio
import logging
from typing import Dict, List, Callable, Awaitable, Optional
import aioredis
from .bus import EventBus
from .types import Event, EventType
from ..config import settings

logger = logging.getLogger(__name__)

class RedisStreamsEventBus(EventBus):
    """Redis Streams ê¸°ë°˜ ì´ë²¤íŠ¸ ë²„ìŠ¤"""
    
    def __init__(self, redis_url: str = None, consumer_group: str = "cache-service"):
        self.redis_url = redis_url or settings.redis_url
        self.consumer_group = consumer_group
        self.redis: Optional[aioredis.Redis] = None
        self.handlers: Dict[EventType, List[Callable]] = {}
        self._running = False
        self._task: Optional[asyncio.Task] = None
    
    async def connect(self):
        """Redis ì—°ê²°"""
        self.redis = await aioredis.from_url(
            self.redis_url,
            encoding="utf-8",
            decode_responses=True
        )
        
        # Consumer Groups ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ)
        for event_type in EventType:
            stream_name = f"events:{event_type.value}"
            try:
                await self.redis.xgroup_create(
                    stream_name,
                    self.consumer_group,
                    id="0",
                    mkstream=True
                )
                logger.info(f"Consumer group created: {self.consumer_group} for {stream_name}")
            except aioredis.ResponseError as e:
                if "BUSYGROUP" not in str(e):
                    raise
                logger.debug(f"Consumer group already exists: {self.consumer_group}")
    
    async def publish(self, event_type: EventType, payload: dict) -> None:
        """ì´ë²¤íŠ¸ ë°œí–‰ (Redis Streams)"""
        if not self.redis:
            await self.connect()
        
        event = Event.create(event_type, payload, source="tts-service")
        stream_name = f"events:{event_type.value}"
        
        try:
            await self.redis.xadd(
                stream_name,
                {
                    "event": event.model_dump_json(),
                    "type": event_type.value
                },
                maxlen=10000  # ìµœëŒ€ 10,000ê°œ ë©”ì‹œì§€ ìœ ì§€
            )
            logger.info(f"Event published: {event_type.value} (id: {event.event_id})")
        except Exception as e:
            logger.error(f"Failed to publish event: {e}", exc_info=True)
            raise
    
    async def subscribe(
        self,
        event_type: EventType,
        handler: Callable[[Event], Awaitable[None]]
    ) -> None:
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        self.handlers[event_type].append(handler)
        logger.info(f"Handler registered for {event_type.value}")
    
    async def _listen(self, consumer_name: str):
        """ì´ë²¤íŠ¸ ìˆ˜ì‹  ë£¨í”„ (Consumer Group)"""
        logger.info(f"Event listener started: {consumer_name}")
        
        while self._running:
            try:
                # ëª¨ë“  ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì½ê¸°
                streams = {
                    f"events:{et.value}": ">"
                    for et in self.handlers.keys()
                }
                
                if not streams:
                    await asyncio.sleep(1)
                    continue
                
                messages = await self.redis.xreadgroup(
                    self.consumer_group,
                    consumer_name,
                    streams,
                    count=10,
                    block=1000
                )
                
                for stream_name, msgs in messages:
                    for msg_id, data in msgs:
                        try:
                            event_data = json.loads(data["event"])
                            event = Event(**event_data)
                            
                            # ì´ë²¤íŠ¸ íƒ€ì… ì¶”ì¶œ
                            event_type = EventType(data["type"])
                            
                            # ëª¨ë“  í•¸ë“¤ëŸ¬ ì‹¤í–‰
                            if event_type in self.handlers:
                                for handler in self.handlers[event_type]:
                                    try:
                                        await handler(event)
                                        logger.debug(f"Handler executed for {event_type.value}")
                                    except Exception as e:
                                        logger.error(f"Handler error: {e}", exc_info=True)
                            
                            # ACK ì²˜ë¦¬
                            await self.redis.xack(
                                stream_name,
                                self.consumer_group,
                                msg_id
                            )
                            logger.debug(f"Event processed and ACKed: {msg_id}")
                            
                        except Exception as e:
                            logger.error(f"Event processing error: {e}", exc_info=True)
                            # ì‹¤íŒ¨í•œ ë©”ì‹œì§€ëŠ” ë‚˜ì¤‘ì— ì¬ì²˜ë¦¬ ê°€ëŠ¥
            
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"Event listening error: {e}", exc_info=True)
                await asyncio.sleep(1)
        
        logger.info(f"Event listener stopped: {consumer_name}")
    
    async def start(self, consumer_name: str = "worker-1") -> None:
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘"""
        if not self.redis:
            await self.connect()
        
        self._running = True
        self._task = asyncio.create_task(self._listen(consumer_name))
        logger.info("Event bus started")
    
    async def stop(self) -> None:
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¤‘ì§€"""
        logger.info("Stopping event bus...")
        self._running = False
        
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        
        if self.redis:
            await self.redis.close()
        
        logger.info("Event bus stopped")
```

#### 2.4 FastAPI í†µí•©
```python
# backend/main.py ìˆ˜ì •
from backend.core.events.redis_streams_bus import RedisStreamsEventBus
from backend.core.config import settings

event_bus: Optional[RedisStreamsEventBus] = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global event_bus
    
    # Startup
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    # Event Bus ì‹œì‘
    event_bus = RedisStreamsEventBus(
        redis_url=settings.redis_url,
        consumer_group="cache-service"
    )
    await event_bus.start(consumer_name=f"worker-{os.getpid()}")
    logger.info("Event bus started")
    
    yield
    
    # Shutdown
    if event_bus:
        await event_bus.stop()
    # ... ê¸°ì¡´ ì½”ë“œ ...
```

### í…ŒìŠ¤íŠ¸ ê³„íš

#### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/unit/events/test_redis_streams_bus.py
import pytest
from backend.core.events.redis_streams_bus import RedisStreamsEventBus
from backend.core.events.types import EventType

@pytest.mark.asyncio
async def test_event_publish():
    """ì´ë²¤íŠ¸ ë°œí–‰ í…ŒìŠ¤íŠ¸"""
    bus = RedisStreamsEventBus(redis_url="redis://redis:6379")
    await bus.connect()
    
    await bus.publish(EventType.VOICE_CREATED, {"voice_id": "test-123"})
    
    # Streamsì—ì„œ í™•ì¸
    messages = await bus.redis.xread({"events:voice.created": "0"}, count=1)
    assert len(messages) > 0

@pytest.mark.asyncio
async def test_event_subscribe():
    """ì´ë²¤íŠ¸ êµ¬ë… í…ŒìŠ¤íŠ¸"""
    bus = RedisStreamsEventBus(redis_url="redis://redis:6379")
    await bus.connect()
    
    received_events = []
    
    async def handler(event):
        received_events.append(event)
    
    await bus.subscribe(EventType.VOICE_CREATED, handler)
    await bus.start(consumer_name="test-worker")
    
    # ì´ë²¤íŠ¸ ë°œí–‰
    await bus.publish(EventType.VOICE_CREATED, {"voice_id": "test-123"})
    
    # ì ì‹œ ëŒ€ê¸°
    await asyncio.sleep(2)
    
    assert len(received_events) > 0
    assert received_events[0].type == EventType.VOICE_CREATED
    
    await bus.stop()
```

#### í†µí•© í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_event_flow.py
@pytest.mark.asyncio
async def test_complete_event_flow():
    """ì „ì²´ ì´ë²¤íŠ¸ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    # 1. Event Bus ì‹œì‘
    bus = RedisStreamsEventBus()
    await bus.start()
    
    # 2. í•¸ë“¤ëŸ¬ ë“±ë¡
    events_received = []
    
    async def handler(event):
        events_received.append(event)
    
    await bus.subscribe(EventType.VOICE_CREATED, handler)
    
    # 3. ì´ë²¤íŠ¸ ë°œí–‰
    await bus.publish(EventType.VOICE_CREATED, {"voice_id": "test-123"})
    
    # 4. ì´ë²¤íŠ¸ ìˆ˜ì‹  í™•ì¸
    await asyncio.sleep(2)
    assert len(events_received) == 1
    
    await bus.stop()
```

### ê²€ì¦ ê¸°ì¤€
- [ ] ì´ë²¤íŠ¸ ë°œí–‰ ì„±ê³µ
- [ ] ì´ë²¤íŠ¸ êµ¬ë… ì„±ê³µ
- [ ] Consumer Groups ì •ìƒ ë™ì‘
- [ ] ACK ì²˜ë¦¬ ì •ìƒ
- [ ] ì—¬ëŸ¬ í•¸ë“¤ëŸ¬ ë™ì‹œ ì‹¤í–‰
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ì •ìƒ
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼

### ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Redis Streams í™•ì¸: `XINFO STREAM events:voice.created`
- [ ] Consumer Groups í™•ì¸: `XINFO GROUPS events:voice.created`
- [ ] Pending ë©”ì‹œì§€ í™•ì¸: `XPENDING events:voice.created cache-service`
- [ ] ì´ë²¤íŠ¸ ë¡œê·¸ í™•ì¸: `docker-compose logs backend | grep Event`

### ë¡¤ë°± ê³„íš
- Event Bus ì½”ë“œë§Œ ì œê±°í•˜ë©´ ê¸°ì¡´ ì‹œìŠ¤í…œì— ì˜í–¥ ì—†ìŒ

---

## Phase 3: Cache Service êµ¬í˜„ (aiocache í†µí•©)

### ëª©í‘œ
- aiocache ê¸°ë°˜ Cache Service êµ¬í˜„
- ë°ì½”ë ˆì´í„° íŒ¨í„´ êµ¬í˜„
- ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
- ìºì‹œ ë¬´íš¨í™” ë¡œì§

### ì‘ì—… ëª©ë¡

#### 3.1 aiocache ì„¤ì •
- [ ] aiocache ì´ˆê¸°í™”
- [ ] Redis ë°±ì—”ë“œ ì„¤ì •
- [ ] Serializer ì„¤ì • (JSON)

#### 3.2 Cache Service êµ¬í˜„
- [ ] CacheService í´ë˜ìŠ¤
- [ ] get/set/delete ë©”ì„œë“œ
- [ ] ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
- [ ] ìºì‹œ ë¬´íš¨í™” ë¡œì§

#### 3.3 ë°ì½”ë ˆì´í„° êµ¬í˜„
- [ ] `@cache_result` ë°ì½”ë ˆì´í„°
- [ ] `@invalidate_cache` ë°ì½”ë ˆì´í„°
- [ ] ë™ì  í‚¤ ë¹Œë” ì§€ì›

#### 3.4 ì˜ì¡´ì„± ì£¼ì… ì„¤ì •
- [ ] CacheService ì˜ì¡´ì„± í•¨ìˆ˜
- [ ] EventBus ì˜ì¡´ì„± í•¨ìˆ˜

### êµ¬í˜„ ì½”ë“œ

#### 3.1 aiocache ì„¤ì •
```python
# backend/core/cache/config.py
from aiocache import Cache
from aiocache.serializers import JsonSerializer
from ..config import settings

def get_cache_config():
    """aiocache ì„¤ì •"""
    return {
        "cache": Cache.REDIS,
        "endpoint": settings.redis_host,
        "port": settings.redis_port,
        "timeout": 1,
        "serializer": JsonSerializer(),
    }

# aiocache ì´ˆê¸°í™”
from aiocache import caches

caches.set_config({
    "default": get_cache_config()
})
```

#### 3.2 Cache Service êµ¬í˜„
```python
# backend/core/cache/service.py
import logging
from typing import Optional, Any, Callable, Awaitable
from functools import wraps
from aiocache import caches
from aiocache.serializers import JsonSerializer
from ..events.bus import EventBus
from ..events.types import Event, EventType

logger = logging.getLogger(__name__)

class CacheService:
    """aiocache ê¸°ë°˜ ìºì‹œ ì„œë¹„ìŠ¤ (ì´ë²¤íŠ¸ ê¸°ë°˜ ë¬´íš¨í™”)"""
    
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self._cache = None
        self._setup_event_handlers()
    
    async def _get_cache(self):
        """ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (lazy initialization)"""
        if not self._cache:
            self._cache = await caches.get("default")
        return self._cache
    
    def _setup_event_handlers(self):
        """ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡"""
        self.event_bus.subscribe(EventType.VOICE_CREATED, self._handle_voice_created)
        self.event_bus.subscribe(EventType.VOICE_UPDATED, self._handle_voice_updated)
        self.event_bus.subscribe(EventType.VOICE_DELETED, self._handle_voice_deleted)
    
    async def get(self, key: str) -> Optional[Any]:
        """ìºì‹œ ì¡°íšŒ"""
        try:
            cache = await self._get_cache()
            return await cache.get(key)
        except Exception as e:
            logger.error(f"Cache get error: {e}", exc_info=True)
            return None
    
    async def set(self, key: str, value: Any, ttl: int = 3600) -> None:
        """ìºì‹œ ì €ì¥"""
        try:
            cache = await self._get_cache()
            await cache.set(key, value, ttl=ttl)
            logger.debug(f"Cache set: {key} (ttl: {ttl}s)")
        except Exception as e:
            logger.error(f"Cache set error: {e}", exc_info=True)
    
    async def delete(self, key: str) -> None:
        """ìºì‹œ ì‚­ì œ"""
        try:
            cache = await self._get_cache()
            await cache.delete(key)
            logger.info(f"Cache deleted: {key}")
        except Exception as e:
            logger.error(f"Cache delete error: {e}", exc_info=True)
    
    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
    async def _handle_voice_created(self, event: Event) -> None:
        """Voice ìƒì„± ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        await self.delete("tts:voices")
        logger.info(f"Cache invalidated: tts:voices (event: {event.event_id})")
    
    async def _handle_voice_updated(self, event: Event) -> None:
        """Voice ìˆ˜ì • ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        await self.delete("tts:voices")
        logger.info(f"Cache invalidated: tts:voices (event: {event.event_id})")
    
    async def _handle_voice_deleted(self, event: Event) -> None:
        """Voice ì‚­ì œ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        await self.delete("tts:voices")
        logger.info(f"Cache invalidated: tts:voices (event: {event.event_id})")


def cache_result(
    key: str,
    ttl: int = 3600,
    key_builder: Optional[Callable] = None
):
    """
    ìºì‹œ ê²°ê³¼ ë°ì½”ë ˆì´í„°
    
    ì‚¬ìš©ë²•:
        @cache_result(key="tts:voices", ttl=3600)
        async def get_voices(self) -> List[Dict[str, Any]]:
            return await api_call()
    
    Args:
        key: ìºì‹œ í‚¤ (ë˜ëŠ” í‚¤ í…œí”Œë¦¿)
        ttl: ìºì‹œ TTL (ì´ˆ)
        key_builder: ë™ì  í‚¤ ìƒì„± í•¨ìˆ˜ (ì„ íƒ)
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            # CacheService ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            cache_service = getattr(self, 'cache_service', None)
            if not cache_service:
                # ì˜ì¡´ì„± ì£¼ì…ìœ¼ë¡œ ë°›ì§€ ì•Šì€ ê²½ìš° ì§ì ‘ í˜¸ì¶œ
                logger.warning(f"CacheService not found for {func.__name__}, skipping cache")
                return await func(self, *args, **kwargs)
            
            # ìºì‹œ í‚¤ ìƒì„±
            if key_builder:
                cache_key = key_builder(*args, **kwargs)
            elif '{' in key:
                # í‚¤ í…œí”Œë¦¿ ì‚¬ìš© (ì˜ˆ: "user:{user_id}")
                try:
                    cache_key = key.format(**kwargs)
                except KeyError:
                    # kwargsì— ì—†ìœ¼ë©´ argsì—ì„œ ì°¾ê¸° (í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜)
                    import inspect
                    sig = inspect.signature(func)
                    bound = sig.bind(self, *args, **kwargs)
                    bound.apply_defaults()
                    cache_key = key.format(**bound.arguments)
            else:
                cache_key = key
            
            # ìºì‹œ ì¡°íšŒ
            cached = await cache_service.get(cache_key)
            if cached is not None:
                logger.debug(f"Cache hit: {cache_key}")
                return cached
            
            # ìºì‹œ ë¯¸ìŠ¤ - ì›ë³¸ í•¨ìˆ˜ ì‹¤í–‰
            logger.debug(f"Cache miss: {cache_key}")
            result = await func(self, *args, **kwargs)
            
            # ìºì‹œ ì €ì¥
            await cache_service.set(cache_key, result, ttl=ttl)
            
            return result
        
        return wrapper
    return decorator


def invalidate_cache(*keys: str):
    """
    ìºì‹œ ë¬´íš¨í™” ë°ì½”ë ˆì´í„°
    
    ì‚¬ìš©ë²•:
        @invalidate_cache("tts:voices")
        async def create_voice_clone(self, ...):
            voice = await create_voice(...)
            return voice
    
    Args:
        keys: ë¬´íš¨í™”í•  ìºì‹œ í‚¤ë“¤
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            # ì›ë³¸ í•¨ìˆ˜ ì‹¤í–‰
            result = await func(self, *args, **kwargs)
            
            # CacheService ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            cache_service = getattr(self, 'cache_service', None)
            if cache_service:
                # ëª¨ë“  í‚¤ ë¬´íš¨í™”
                for key in keys:
                    if '{' in key:
                        # í‚¤ í…œí”Œë¦¿ ì‚¬ìš©
                        try:
                            formatted_key = key.format(**kwargs)
                        except KeyError:
                            import inspect
                            sig = inspect.signature(func)
                            bound = sig.bind(self, *args, **kwargs)
                            bound.apply_defaults()
                            formatted_key = key.format(**bound.arguments)
                        await cache_service.delete(formatted_key)
                    else:
                        await cache_service.delete(key)
            
            return result
        
        return wrapper
    return decorator
```

#### 3.3 ì˜ì¡´ì„± ì£¼ì… ì„¤ì •
```python
# backend/core/dependencies.pyì— ì¶”ê°€
from backend.core.cache.service import CacheService
from backend.core.events.redis_streams_bus import RedisStreamsEventBus
from backend.core.config import settings

# ì „ì—­ Event Bus (lifespanì—ì„œ ì´ˆê¸°í™”)
_event_bus: Optional[RedisStreamsEventBus] = None

def set_event_bus(event_bus: RedisStreamsEventBus):
    """Event Bus ì„¤ì • (lifespanì—ì„œ í˜¸ì¶œ)"""
    global _event_bus
    _event_bus = event_bus

def get_event_bus() -> RedisStreamsEventBus:
    """Event Bus ì˜ì¡´ì„±"""
    if not _event_bus:
        raise RuntimeError("Event bus not initialized. Call set_event_bus() first.")
    return _event_bus

def get_cache_service(
    event_bus: RedisStreamsEventBus = Depends(get_event_bus)
) -> CacheService:
    """CacheService ì˜ì¡´ì„± ì£¼ì…"""
    return CacheService(event_bus=event_bus)
```

### í…ŒìŠ¤íŠ¸ ê³„íš

#### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/unit/cache/test_cache_service.py
@pytest.mark.asyncio
async def test_cache_get_set():
    """ìºì‹œ ì¡°íšŒ/ì €ì¥ í…ŒìŠ¤íŠ¸"""
    event_bus = MockEventBus()
    cache_service = CacheService(event_bus=event_bus)
    
    await cache_service.set("test:key", {"data": "value"}, ttl=60)
    result = await cache_service.get("test:key")
    
    assert result == {"data": "value"}

@pytest.mark.asyncio
async def test_cache_delete():
    """ìºì‹œ ì‚­ì œ í…ŒìŠ¤íŠ¸"""
    event_bus = MockEventBus()
    cache_service = CacheService(event_bus=event_bus)
    
    await cache_service.set("test:key", "value")
    await cache_service.delete("test:key")
    result = await cache_service.get("test:key")
    
    assert result is None

@pytest.mark.asyncio
async def test_cache_decorator():
    """ìºì‹œ ë°ì½”ë ˆì´í„° í…ŒìŠ¤íŠ¸"""
    event_bus = MockEventBus()
    cache_service = CacheService(event_bus=event_bus)
    
    class TestService:
        def __init__(self):
            self.cache_service = cache_service
            self.call_count = 0
        
        @cache_result(key="test:key", ttl=60)
        async def get_data(self):
            self.call_count += 1
            return {"data": "value"}
    
    service = TestService()
    
    # ì²« í˜¸ì¶œ - ìºì‹œ ë¯¸ìŠ¤
    result1 = await service.get_data()
    assert result1 == {"data": "value"}
    assert service.call_count == 1
    
    # ë‘ ë²ˆì§¸ í˜¸ì¶œ - ìºì‹œ íˆíŠ¸
    result2 = await service.get_data()
    assert result2 == {"data": "value"}
    assert service.call_count == 1  # í˜¸ì¶œ ì•ˆ ë¨
```

#### í†µí•© í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_cache_with_events.py
@pytest.mark.asyncio
async def test_cache_invalidation_on_event():
    """ì´ë²¤íŠ¸ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™” í…ŒìŠ¤íŠ¸"""
    # 1. Event Bus ì‹œì‘
    event_bus = RedisStreamsEventBus()
    await event_bus.start()
    
    # 2. Cache Service ìƒì„±
    cache_service = CacheService(event_bus=event_bus)
    
    # 3. ìºì‹œ ì €ì¥
    await cache_service.set("tts:voices", [{"id": "1"}])
    
    # 4. ì´ë²¤íŠ¸ ë°œí–‰
    await event_bus.publish(EventType.VOICE_CREATED, {"voice_id": "new-voice"})
    
    # 5. ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°
    await asyncio.sleep(2)
    
    # 6. ìºì‹œ ë¬´íš¨í™” í™•ì¸
    result = await cache_service.get("tts:voices")
    assert result is None
    
    await event_bus.stop()
```

### ê²€ì¦ ê¸°ì¤€
- [ ] ìºì‹œ ì¡°íšŒ/ì €ì¥ ì„±ê³µ
- [ ] ìºì‹œ ì‚­ì œ ì„±ê³µ
- [ ] ë°ì½”ë ˆì´í„° ì •ìƒ ë™ì‘
- [ ] ì´ë²¤íŠ¸ ê¸°ë°˜ ë¬´íš¨í™” ì •ìƒ
- [ ] TTL ì •ìƒ ë™ì‘
- [ ] ë™ì  í‚¤ ë¹Œë” ì •ìƒ
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼

### ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Redis í‚¤ í™•ì¸: `KEYS tts:*`
- [ ] ìºì‹œ TTL í™•ì¸: `TTL tts:voices`
- [ ] ì´ë²¤íŠ¸ ë¡œê·¸ í™•ì¸: `docker-compose logs backend | grep Cache`
- [ ] aiocache ë¡œê·¸ í™•ì¸

### ë¡¤ë°± ê³„íš
- CacheService ì½”ë“œë§Œ ì œê±°í•˜ë©´ ê¸°ì¡´ ì‹œìŠ¤í…œì— ì˜í–¥ ì—†ìŒ

---

## Phase 4: Service Layer í†µí•©

### ëª©í‘œ
- TTSServiceì— ìºì‹± ì ìš©
- ì´ë²¤íŠ¸ ë°œí–‰ ì¶”ê°€
- ì˜ì¡´ì„± ì£¼ì… ì—…ë°ì´íŠ¸
- API ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •

### ì‘ì—… ëª©ë¡

#### 4.1 TTSService ìˆ˜ì •
- [ ] CacheService, EventBus ì˜ì¡´ì„± ì¶”ê°€
- [ ] `get_voices()`ì— `@cache_result` ë°ì½”ë ˆì´í„° ì ìš©
- [ ] `create_voice_clone()`ì— ì´ë²¤íŠ¸ ë°œí–‰ ì¶”ê°€ (ì¶”í›„ êµ¬í˜„ ì‹œ)

#### 4.2 ì˜ì¡´ì„± ì£¼ì… ì—…ë°ì´íŠ¸
- [ ] `get_tts_service()` í•¨ìˆ˜ ìˆ˜ì •
- [ ] CacheService, EventBus ì£¼ì…

#### 4.3 API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
- [ ] ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ ë™ì‘ í™•ì¸
- [ ] ìºì‹œ ë™ì‘ í™•ì¸

### êµ¬í˜„ ì½”ë“œ

#### 4.1 TTSService ìˆ˜ì •
```python
# backend/features/tts/service.py
from ..core.cache.service import cache_result
from ..core.events.bus import EventBus
from ..core.events.types import EventType

class TTSService:
    def __init__(
        self,
        audio_repo: AudioRepository,
        storage_service: AbstractStorageService,
        ai_factory: AIProviderFactory,
        db_session: AsyncSession,
        cache_service: CacheService,  # ì¶”ê°€
        event_bus: EventBus,  # ì¶”ê°€
    ):
        self.audio_repo = audio_repo
        self.storage_service = storage_service
        self.ai_factory = ai_factory
        self.db_session = db_session
        self.cache_service = cache_service  # ë°ì½”ë ˆì´í„°ì—ì„œ ì‚¬ìš©
        self.event_bus = event_bus
    
    @cache_result(key="tts:voices", ttl=3600)
    async def get_voices(self) -> List[Dict[str, Any]]:
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ì¡°íšŒ (ìºì‹± ìë™ ì ìš©)
        
        ë°ì½”ë ˆì´í„°ê°€ ìë™ìœ¼ë¡œ:
        1. ìºì‹œ ì¡°íšŒ
        2. ìºì‹œ ë¯¸ìŠ¤ ì‹œ API í˜¸ì¶œ
        3. ê²°ê³¼ ìºì‹œ ì €ì¥
        """
        try:
            tts_provider = self.ai_factory.get_tts_provider()
        except TTSAPIKeyNotConfiguredException:
            raise
        except Exception as e:
            raise TTSGenerationFailedException(reason=f"TTS Provider ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        
        try:
            voices = await tts_provider.get_available_voices()
            return voices
        except (TTSAPIKeyNotConfiguredException, TTSAPIAuthenticationFailedException):
            raise
        except Exception as e:
            raise TTSGenerationFailedException(reason=f"ìŒì„± ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
    
    # ì¶”í›„ Voice Clone ìƒì„± ì‹œ
    async def create_voice_clone(
        self,
        user_id: uuid.UUID,
        name: str,
        audio_file: bytes,
    ) -> Dict[str, Any]:
        """Voice Clone ìƒì„± (ì´ë²¤íŠ¸ ë°œí–‰ìœ¼ë¡œ ìºì‹œ ë¬´íš¨í™”)"""
        tts_provider = self.ai_factory.get_tts_provider()
        voice = await tts_provider.clone_voice(name=name, audio_file=audio_file)
        
        # ì´ë²¤íŠ¸ ë°œí–‰ (Redis Streams)
        await self.event_bus.publish(
            EventType.VOICE_CREATED,
            {
                "voice_id": voice["voice_id"],
                "name": voice["name"],
                "user_id": str(user_id),
            }
        )
        
        return voice
```

#### 4.2 ì˜ì¡´ì„± ì£¼ì… ì—…ë°ì´íŠ¸
```python
# backend/api/v1/endpoints/tts.py
from backend.core.dependencies import get_cache_service, get_event_bus

def get_tts_service(
    db: AsyncSession = Depends(get_db),
    storage_service = Depends(get_storage_service),
    ai_factory = Depends(get_ai_factory),
    cache_service: CacheService = Depends(get_cache_service),  # ì¶”ê°€
    event_bus: EventBus = Depends(get_event_bus),  # ì¶”ê°€
) -> TTSService:
    """TTSService ì˜ì¡´ì„± ì£¼ì…"""
    audio_repo = AudioRepository(db)
    return TTSService(
        audio_repo=audio_repo,
        storage_service=storage_service,
        ai_factory=ai_factory,
        db_session=db,
        cache_service=cache_service,
        event_bus=event_bus,
    )
```

### í…ŒìŠ¤íŠ¸ ê³„íš

#### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/unit/tts/test_tts_service_caching.py
@pytest.mark.asyncio
async def test_get_voices_caching():
    """get_voices ìºì‹± í…ŒìŠ¤íŠ¸"""
    # Mock ì„¤ì •
    mock_cache_service = MockCacheService()
    mock_event_bus = MockEventBus()
    mock_tts_provider = MockTTSProvider()
    
    service = TTSService(
        audio_repo=MockAudioRepository(),
        storage_service=MockStorageService(),
        ai_factory=MockAIFactory(mock_tts_provider),
        db_session=MockSession(),
        cache_service=mock_cache_service,
        event_bus=mock_event_bus,
    )
    
    # ì²« í˜¸ì¶œ - ìºì‹œ ë¯¸ìŠ¤
    result1 = await service.get_voices()
    assert mock_tts_provider.get_available_voices_call_count == 1
    
    # ë‘ ë²ˆì§¸ í˜¸ì¶œ - ìºì‹œ íˆíŠ¸
    result2 = await service.get_voices()
    assert mock_tts_provider.get_available_voices_call_count == 1  # í˜¸ì¶œ ì•ˆ ë¨
    assert result1 == result2
```

#### í†µí•© í…ŒìŠ¤íŠ¸
```python
# tests/integration/test_tts_api_caching.py
@pytest.mark.asyncio
async def test_voices_api_caching():
    """Voices API ìºì‹± í†µí•© í…ŒìŠ¤íŠ¸"""
    # 1. ì²« ìš”ì²­ - ìºì‹œ ë¯¸ìŠ¤
    response1 = await client.get("/api/v1/tts/voices")
    assert response1.status_code == 200
    
    # 2. ë‘ ë²ˆì§¸ ìš”ì²­ - ìºì‹œ íˆíŠ¸ (ì‘ë‹µ ì‹œê°„ í™•ì¸)
    import time
    start = time.time()
    response2 = await client.get("/api/v1/tts/voices")
    elapsed = time.time() - start
    
    assert response2.status_code == 200
    assert elapsed < 0.1  # ìºì‹œ íˆíŠ¸ëŠ” ë§¤ìš° ë¹ ë¦„
    assert response1.json() == response2.json()
```

#### E2E í…ŒìŠ¤íŠ¸
```python
# tests/e2e/test_cache_invalidation_flow.py
@pytest.mark.asyncio
async def test_complete_cache_invalidation_flow():
    """ì „ì²´ ìºì‹œ ë¬´íš¨í™” í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    # 1. Voices ì¡°íšŒ (ìºì‹œ ì €ì¥)
    response1 = await client.get("/api/v1/tts/voices")
    voices1 = response1.json()
    
    # 2. Voice ìƒì„± (ì´ë²¤íŠ¸ ë°œí–‰)
    # Note: Voice Clone ì—”ë“œí¬ì¸íŠ¸ê°€ êµ¬í˜„ë˜ë©´ ì‹¤ì œë¡œ í…ŒìŠ¤íŠ¸
    # í˜„ì¬ëŠ” ì´ë²¤íŠ¸ ì§ì ‘ ë°œí–‰
    event_bus = get_event_bus()
    await event_bus.publish(
        EventType.VOICE_CREATED,
        {"voice_id": "new-voice-123", "name": "New Voice"}
    )
    
    # 3. ì´ë²¤íŠ¸ ì²˜ë¦¬ ëŒ€ê¸°
    await asyncio.sleep(2)
    
    # 4. Voices ì¬ì¡°íšŒ (ìºì‹œ ë¬´íš¨í™”ë˜ì–´ ìƒˆë¡œ ì¡°íšŒ)
    response2 = await client.get("/api/v1/tts/voices")
    voices2 = response2.json()
    
    # 5. ìƒˆ ìŒì„±ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì‹¤ì œ API ì‘ë‹µì— ë”°ë¼)
    # assert len(voices2) > len(voices1)  # ìƒˆ ìŒì„± ì¶”ê°€ í™•ì¸
```

### ê²€ì¦ ê¸°ì¤€
- [ ] `get_voices()` ë°ì½”ë ˆì´í„° ì •ìƒ ë™ì‘
- [ ] ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ì •ìƒ
- [ ] API ì‘ë‹µ ì‹œê°„ ê°œì„  í™•ì¸
- [ ] ì´ë²¤íŠ¸ ë°œí–‰ ì •ìƒ (Voice ìƒì„± ì‹œ)
- [ ] ìºì‹œ ë¬´íš¨í™” ì •ìƒ
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼

### ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] API ë¡œê·¸ í™•ì¸: `docker-compose logs backend | grep tts`
- [ ] ìºì‹œ í‚¤ í™•ì¸: `docker-compose exec redis redis-cli KEYS tts:*`
- [ ] ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ í™•ì¸: `XINFO STREAM events:voice.created`
- [ ] ì‘ë‹µ ì‹œê°„ í™•ì¸: API í˜¸ì¶œ ì‹œ `time` ì¸¡ì •

### ë¡¤ë°± ê³„íš
- ë°ì½”ë ˆì´í„°ë§Œ ì œê±°í•˜ë©´ ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ë³µê·€

---

## Phase 5: ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

### ëª©í‘œ
- ìºì‹œ íˆíŠ¸ìœ¨ ëª¨ë‹ˆí„°ë§
- ì´ë²¤íŠ¸ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§
- ì„±ëŠ¥ ìµœì í™”
- ë¡œê¹… ê°œì„ 

### ì‘ì—… ëª©ë¡

#### 5.1 ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ ì¶”ì 
- [ ] ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œê°„ ì¶”ì 
- [ ] API ì‘ë‹µ ì‹œê°„ ì¶”ì 
- [ ] Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

#### 5.2 ë¡œê¹… ê°œì„ 
- [ ] êµ¬ì¡°í™”ëœ ë¡œê¹…
- [ ] ìºì‹œ ë™ì‘ ë¡œê·¸
- [ ] ì´ë²¤íŠ¸ ë°œí–‰/ì²˜ë¦¬ ë¡œê·¸

#### 5.3 ì„±ëŠ¥ ìµœì í™”
- [ ] TTL ìµœì í™”
- [ ] ìºì‹œ í‚¤ ìµœì í™”
- [ ] ì´ë²¤íŠ¸ ì²˜ë¦¬ ìµœì í™”

### êµ¬í˜„ ì½”ë“œ

#### 5.1 ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­
```python
# backend/core/cache/metrics.py
from typing import Dict
from collections import defaultdict
import time

class CacheMetrics:
    """ìºì‹œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    
    def __init__(self):
        self.hits = 0
        self.misses = 0
        self.set_operations = 0
        self.delete_operations = 0
        self.total_get_time = 0.0
        self.total_set_time = 0.0
    
    def record_hit(self, duration: float):
        self.hits += 1
        self.total_get_time += duration
    
    def record_miss(self, duration: float):
        self.misses += 1
        self.total_get_time += duration
    
    def record_set(self, duration: float):
        self.set_operations += 1
        self.total_set_time += duration
    
    def record_delete(self):
        self.delete_operations += 1
    
    @property
    def hit_rate(self) -> float:
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0
    
    @property
    def avg_get_time(self) -> float:
        total = self.hits + self.misses
        return self.total_get_time / total if total > 0 else 0.0
    
    def get_stats(self) -> Dict:
        return {
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": self.hit_rate,
            "set_operations": self.set_operations,
            "delete_operations": self.delete_operations,
            "avg_get_time_ms": self.avg_get_time * 1000,
        }

# ì „ì—­ ë©”íŠ¸ë¦­
cache_metrics = CacheMetrics()
```

#### 5.2 ë¡œê¹… ê°œì„ 
```python
# backend/core/cache/service.pyì— ì¶”ê°€
import structlog

logger = structlog.get_logger(__name__)

class CacheService:
    async def get(self, key: str) -> Optional[Any]:
        start = time.time()
        try:
            cache = await self._get_cache()
            result = await cache.get(key)
            duration = time.time() - start
            
            if result is not None:
                cache_metrics.record_hit(duration)
                logger.info(
                    "cache_hit",
                    key=key,
                    duration_ms=duration * 1000
                )
            else:
                cache_metrics.record_miss(duration)
                logger.info(
                    "cache_miss",
                    key=key,
                    duration_ms=duration * 1000
                )
            
            return result
        except Exception as e:
            logger.error("cache_get_error", key=key, error=str(e))
            return None
```

### í…ŒìŠ¤íŠ¸ ê³„íš

#### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```python
# tests/performance/test_cache_performance.py
@pytest.mark.asyncio
async def test_cache_performance():
    """ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    service = get_tts_service()
    
    # ì²« í˜¸ì¶œ (ìºì‹œ ë¯¸ìŠ¤)
    start = time.time()
    await service.get_voices()
    miss_time = time.time() - start
    
    # ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ íˆíŠ¸)
    start = time.time()
    await service.get_voices()
    hit_time = time.time() - start
    
    # ìºì‹œ íˆíŠ¸ê°€ 10ë°° ì´ìƒ ë¹ ë¥¸ì§€ í™•ì¸
    assert hit_time < miss_time / 10
    assert hit_time < 0.1  # 100ms ì´í•˜
```

### ê²€ì¦ ê¸°ì¤€
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ 90% ì´ìƒ
- [ ] API ì‘ë‹µ ì‹œê°„ 5ë°° ì´ìƒ ê°œì„ 
- [ ] ì´ë²¤íŠ¸ ì²˜ë¦¬ ì§€ì—° 1ì´ˆ ì´í•˜
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ ë²”ìœ„
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼

---

## ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ì¸í”„ë¼
- [ ] Redis ì»¨í…Œì´ë„ˆ ì¶”ê°€
- [ ] aiocache ì„¤ì¹˜
- [ ] ì„¤ì • íŒŒì¼ ì¶”ê°€
- [ ] ì—°ê²° í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

### Phase 2: ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ
- [ ] ì´ë²¤íŠ¸ íƒ€ì… ì •ì˜
- [ ] Event Bus êµ¬í˜„
- [ ] Redis Streams í†µí•©
- [ ] FastAPI lifespan í†µí•©
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

### Phase 3: Cache Service
- [ ] aiocache í†µí•©
- [ ] CacheService êµ¬í˜„
- [ ] ë°ì½”ë ˆì´í„° êµ¬í˜„
- [ ] ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

### Phase 4: Service í†µí•©
- [ ] TTSService ìˆ˜ì •
- [ ] ì˜ì¡´ì„± ì£¼ì… ì—…ë°ì´íŠ¸
- [ ] API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] E2E í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

### Phase 5: ëª¨ë‹ˆí„°ë§
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- [ ] ë¡œê¹… ê°œì„ 
- [ ] ì„±ëŠ¥ ìµœì í™”
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

---

## ê° Phaseë³„ í…ŒìŠ¤íŠ¸-êµ¬í˜„-ë””ë²„ê¹… ë£¨í”„

### ë£¨í”„ í”„ë¡œì„¸ìŠ¤

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase ì‹œì‘     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. êµ¬í˜„        â”‚
â”‚  - ì½”ë“œ ì‘ì„±    â”‚
â”‚  - ê¸°ë³¸ ë™ì‘    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ â”‚
â”‚  - í•¨ìˆ˜ë³„ í…ŒìŠ¤íŠ¸â”‚
â”‚  - Mock ì‚¬ìš©    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ í†µê³¼?   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    NO   â”‚   YES
    â”‚    â”‚    â”‚
    â–¼    â”‚    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. ë””ë²„ê¹…      â”‚
â”‚  - ë¡œê·¸ í™•ì¸    â”‚
â”‚  - ë¬¸ì œ ìˆ˜ì •    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. í†µí•© í…ŒìŠ¤íŠ¸ â”‚
â”‚  - ì „ì²´ í”Œë¡œìš°  â”‚
â”‚  - ì‹¤ì œ í™˜ê²½    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ í†µê³¼?   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    NO   â”‚   YES
    â”‚    â”‚    â”‚
    â–¼    â”‚    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ê²€ì¦        â”‚
â”‚  - ì„±ëŠ¥ í™•ì¸    â”‚
â”‚  - ë©”íŠ¸ë¦­ í™•ì¸  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ í†µê³¼?   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    NO   â”‚   YES
    â”‚    â”‚    â”‚
    â–¼    â”‚    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. ë¬¸ì„œí™”      â”‚
â”‚  - ì½”ë“œ ì£¼ì„    â”‚
â”‚  - README ì—…ë°ì´íŠ¸â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase ì™„ë£Œ     â”‚
â”‚  â†’ ë‹¤ìŒ Phase   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ë””ë²„ê¹… ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œ ë° í•´ê²°

#### 1. Redis ì—°ê²° ì‹¤íŒ¨
**ì¦ìƒ**: `ConnectionError` ë˜ëŠ” `TimeoutError`

**í•´ê²°**:
```bash
# Redis ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps redis

# Redis ë¡œê·¸ í™•ì¸
docker-compose logs redis

# ë„¤íŠ¸ì›Œí¬ í™•ì¸
docker network inspect moriai-network

# Redis ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸
docker-compose exec redis redis-cli ping
```

#### 2. ìºì‹œê°€ ë™ì‘í•˜ì§€ ì•ŠìŒ
**ì¦ìƒ**: í•­ìƒ ìºì‹œ ë¯¸ìŠ¤

**í•´ê²°**:
- CacheService ì¸ìŠ¤í„´ìŠ¤ í™•ì¸: `self.cache_service` ì¡´ì¬ ì—¬ë¶€
- ë°ì½”ë ˆì´í„° ì ìš© í™•ì¸: `@cache_result` ë°ì½”ë ˆì´í„° í™•ì¸
- Redis í‚¤ í™•ì¸: `KEYS tts:*`
- ë¡œê·¸ í™•ì¸: ìºì‹œ ë™ì‘ ë¡œê·¸

#### 3. ì´ë²¤íŠ¸ê°€ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ
**ì¦ìƒ**: ì´ë²¤íŠ¸ ë°œí–‰ í›„ ìºì‹œ ë¬´íš¨í™” ì•ˆ ë¨

**í•´ê²°**:
- Event Bus ì‹œì‘ í™•ì¸: lifespanì—ì„œ `start()` í˜¸ì¶œ í™•ì¸
- Consumer Groups í™•ì¸: `XINFO GROUPS events:voice.created`
- Pending ë©”ì‹œì§€ í™•ì¸: `XPENDING events:voice.created cache-service`
- í•¸ë“¤ëŸ¬ ë“±ë¡ í™•ì¸: `subscribe()` í˜¸ì¶œ í™•ì¸

#### 4. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
**ì¦ìƒ**: Redis ë©”ëª¨ë¦¬ ê³„ì† ì¦ê°€

**í•´ê²°**:
- Streams ê¸¸ì´ í™•ì¸: `XLEN events:voice.created`
- MaxLen ì„¤ì • í™•ì¸: `XADD` ì‹œ `maxlen` ì˜µì…˜
- TTL í™•ì¸: ìºì‹œ TTL ì„¤ì • í™•ì¸
- ë©”ëª¨ë¦¬ ì •ë¦¬: `MEMORY DOCTOR` ì‹¤í–‰

---

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ëª©í‘œ ì§€í‘œ

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|--------|------|----------|
| ìºì‹œ íˆíŠ¸ìœ¨ | > 90% | `hits / (hits + misses)` |
| API ì‘ë‹µ ì‹œê°„ (ìºì‹œ íˆíŠ¸) | < 100ms | API í˜¸ì¶œ ì‹œê°„ ì¸¡ì • |
| API ì‘ë‹µ ì‹œê°„ (ìºì‹œ ë¯¸ìŠ¤) | < 2s | API í˜¸ì¶œ ì‹œê°„ ì¸¡ì • |
| ì´ë²¤íŠ¸ ì²˜ë¦¬ ì§€ì—° | < 1s | ì´ë²¤íŠ¸ ë°œí–‰ â†’ ì²˜ë¦¬ ì‹œê°„ |
| Redis ë©”ëª¨ë¦¬ ì‚¬ìš© | < 100MB | `INFO memory` |

### ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
```python
# tests/performance/benchmark_cache.py
@pytest.mark.asyncio
async def benchmark_cache_performance():
    """ìºì‹œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    service = get_tts_service()
    
    # 100íšŒ í˜¸ì¶œ
    times = []
    for _ in range(100):
        start = time.time()
        await service.get_voices()
        times.append(time.time() - start)
    
    avg_time = sum(times) / len(times)
    p95_time = sorted(times)[95]
    
    print(f"Average: {avg_time*1000:.2f}ms")
    print(f"P95: {p95_time*1000:.2f}ms")
    
    assert avg_time < 0.1  # 100ms ì´í•˜
```

---

## ë¡¤ë°± ê³„íš

### Phaseë³„ ë¡¤ë°±

#### Phase 1 ë¡¤ë°±
```bash
# Redis ì„œë¹„ìŠ¤ë§Œ ì œê±°
docker-compose down redis
# docker-compose.ymlì—ì„œ redis ì„œë¹„ìŠ¤ ì œê±°
```

#### Phase 2 ë¡¤ë°±
```python
# Event Bus ì½”ë“œë§Œ ì œê±°
# lifespanì—ì„œ event_bus.start() ì œê±°
```

#### Phase 3 ë¡¤ë°±
```python
# CacheService ì½”ë“œë§Œ ì œê±°
# ë°ì½”ë ˆì´í„° ì œê±°
```

#### Phase 4 ë¡¤ë°±
```python
# TTSServiceì—ì„œ ë°ì½”ë ˆì´í„°ë§Œ ì œê±°
# ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ë³µê·€
```

---

## ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ëŠ¥ ê²€ì¦
- [ ] ìºì‹œ ì¡°íšŒ/ì €ì¥ ì •ìƒ
- [ ] ìºì‹œ ë¬´íš¨í™” ì •ìƒ
- [ ] ì´ë²¤íŠ¸ ë°œí–‰/êµ¬ë… ì •ìƒ
- [ ] ë°ì½”ë ˆì´í„° ì •ìƒ ë™ì‘
- [ ] TTL ì •ìƒ ë™ì‘

### ì„±ëŠ¥ ê²€ì¦
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ 90% ì´ìƒ
- [ ] API ì‘ë‹µ ì‹œê°„ 5ë°° ì´ìƒ ê°œì„ 
- [ ] ì´ë²¤íŠ¸ ì²˜ë¦¬ ì§€ì—° 1ì´ˆ ì´í•˜
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ

### ì•ˆì •ì„± ê²€ì¦
- [ ] Redis ì¥ì•  ì‹œ graceful degradation
- [ ] ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì¬ì²˜ë¦¬
- [ ] ë™ì‹œì„± í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ í†µê³¼

---

## ì˜ˆìƒ ì¼ì •

- **Phase 1**: 1-2ì‹œê°„
- **Phase 2**: 2-3ì‹œê°„
- **Phase 3**: 2-3ì‹œê°„
- **Phase 4**: 2-3ì‹œê°„
- **Phase 5**: 1-2ì‹œê°„

**ì´ ì˜ˆìƒ ì‹œê°„**: 8-13ì‹œê°„ (1-2ì¼)

---

## ë‹¤ìŒ ë‹¨ê³„

1. **Phase 1ë¶€í„° ì‹œì‘**: ì¸í”„ë¼ êµ¬ì¶•
2. **ê° Phase ì™„ë£Œ í›„ ê²€ì¦**: í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
3. **ë¬¸ì œ ë°œìƒ ì‹œ ë””ë²„ê¹…**: ë£¨í”„ ë°˜ë³µ
4. **ë¬¸ì„œí™”**: ê° Phase ì™„ë£Œ ì‹œ ë¬¸ì„œ ì—…ë°ì´íŠ¸

